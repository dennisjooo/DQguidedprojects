{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyzing Stock Prices\n",
    "---\n",
    "\n",
    "In this guided project, we'll work with stock market data that was downloaded from [Yahoo Finance](https://finance.yahoo.com/) using the [yahoo_finance](https://pypi.python.org/pypi/yahoo-finance) Python package. This data consists of the daily stock prices from `2007-1-1` to `2017-04-17` for several hundred stock symbols traded on the [NASDAQ](http://www.nasdaq.com/) stock exchange, stored in the `prices` folder. The `download_data.py` script in the same folder as the Jupyter notebook was used to download all of the stock price data. Each file in the prices folder is named for a specific stock symbol, and contains the:\n",
    "\n",
    "- `date` -- date that the data is from.\n",
    "- `close` -- the closing price on that day, which is the price when the trading day ends.\n",
    "- `open` -- the opening price on that day, which is the price when the trading day starts.\n",
    "- `high` -- the highest price the stock reached during trading.\n",
    "- `low` -- the lowest price the stock reached during trading.\n",
    "- `volume` -- the number of shares that were traded during the day.\n",
    "\n",
    "Stock trading doesn't happen on certain days, like weekends and holidays, so there are gaps between days -- we only have data for days on which trading happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stock Price Data\n",
    "We will begin by reading all the `CSV` files from the `prices` folder and storing them in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Creating an empty dictionary\n",
    "stock_prices = {}\n",
    "\n",
    "# Looping through every entry in the folder\n",
    "for fn in os.listdir(\"prices\"):\n",
    "    name = fn.split(\".\")[0]\n",
    "    stock_prices[name] = pd.read_csv(os.path.join(\"prices\", fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether we have successfully imported the data in, we will display the data for Apple (which is denoted by `AAPL`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>83.800002</td>\n",
       "      <td>86.289999</td>\n",
       "      <td>86.579999</td>\n",
       "      <td>81.899999</td>\n",
       "      <td>309579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>85.659998</td>\n",
       "      <td>84.050001</td>\n",
       "      <td>85.949998</td>\n",
       "      <td>83.820003</td>\n",
       "      <td>211815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>85.049997</td>\n",
       "      <td>85.770000</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>208685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>85.470000</td>\n",
       "      <td>85.959998</td>\n",
       "      <td>86.529998</td>\n",
       "      <td>85.280003</td>\n",
       "      <td>199276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>92.570003</td>\n",
       "      <td>86.450003</td>\n",
       "      <td>92.979999</td>\n",
       "      <td>85.150000</td>\n",
       "      <td>837324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-10</td>\n",
       "      <td>96.999997</td>\n",
       "      <td>94.749999</td>\n",
       "      <td>97.800002</td>\n",
       "      <td>93.450003</td>\n",
       "      <td>738220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>95.800003</td>\n",
       "      <td>95.940000</td>\n",
       "      <td>96.779999</td>\n",
       "      <td>95.100000</td>\n",
       "      <td>360063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-12</td>\n",
       "      <td>94.620003</td>\n",
       "      <td>94.590002</td>\n",
       "      <td>95.059999</td>\n",
       "      <td>93.229998</td>\n",
       "      <td>328172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-16</td>\n",
       "      <td>97.099999</td>\n",
       "      <td>95.680000</td>\n",
       "      <td>97.250003</td>\n",
       "      <td>95.450002</td>\n",
       "      <td>311019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-01-17</td>\n",
       "      <td>94.949997</td>\n",
       "      <td>97.560003</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>94.820001</td>\n",
       "      <td>411565000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      close       open       high        low     volume\n",
       "0  2007-01-03  83.800002  86.289999  86.579999  81.899999  309579900\n",
       "1  2007-01-04  85.659998  84.050001  85.949998  83.820003  211815100\n",
       "2  2007-01-05  85.049997  85.770000  86.199997  84.400002  208685400\n",
       "3  2007-01-08  85.470000  85.959998  86.529998  85.280003  199276700\n",
       "4  2007-01-09  92.570003  86.450003  92.979999  85.150000  837324600\n",
       "5  2007-01-10  96.999997  94.749999  97.800002  93.450003  738220000\n",
       "6  2007-01-11  95.800003  95.940000  96.779999  95.100000  360063200\n",
       "7  2007-01-12  94.620003  94.590002  95.059999  93.229998  328172600\n",
       "8  2007-01-16  97.099999  95.680000  97.250003  95.450002  311019100\n",
       "9  2007-01-17  94.949997  97.560003  97.599998  94.820001  411565000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying Apple's stock\n",
    "stock_prices['aapl'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Minimum and Maximum Average Closing Prices\n",
    "We will try and calculate the minimum and the maximum closing prices for every index we have. To do this, we can use the `DataFrame.mean()` method from the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary to store the closing prices\n",
    "avg_closing_prices = {}\n",
    "\n",
    "# Iterating through every symbols\n",
    "for stock_sym in stock_prices:\n",
    "    avg_closing_prices[stock_sym] = stock_prices[stock_sym][\"close\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully stored the average closing price to a dictionary. The problem is that we cannot actualy sort them right away since they are ordered based on the keys which are strings. We can actually flip the order and store them in a list, sort them, and pull out the maximum and minimum that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 maximum average closing prices:\n",
      "(275.13407757104255, 'amzn')\n",
      "(257.1765404023166, 'aapl')\n",
      "(230.2946601100386, 'cme') \n",
      "\n",
      "3 minimum average closing prices:\n",
      "(0.8122763011583011, 'blfs')\n",
      "(0.8241009938223938, 'apdn')\n",
      "(0.901011583011583, 'bmra')\n"
     ]
    }
   ],
   "source": [
    "# Flipping the order\n",
    "pairs = [(avg_closing_prices[stock_sym], stock_sym) for stock_sym in stock_prices]\n",
    "\n",
    "# Sorting the list\n",
    "pairs.sort(reverse = True)\n",
    "\n",
    "# Getting the 3 highest average closing price\n",
    "print(\"3 maximum average closing prices:\")\n",
    "print(pairs[0])\n",
    "print(pairs[1])\n",
    "print(pairs[2],'\\n')\n",
    "\n",
    "# Getting the 3 lowest average closing price\n",
    "print(\"3 minimum average closing prices:\")\n",
    "print(pairs[-1])\n",
    "print(pairs[-2])\n",
    "print(pairs[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the three stocks with the highest average closing price in that period are Amazon (`AMZN`), Apple (`AAPL`), and CME Group (`CME`). Contrary to that, the three lowest are Biolife Solutions (`BLFS`), Applied DNA Sciences (`APDN`), and Biomerica (`BMRA`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grouping Trades per Day\n",
    "We will now group trades per day, more precisely, for each day, we'll want a list of pairs `(volume, stock_symbol)` of all trades that occurred on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary\n",
    "trades_by_day = {}\n",
    "\n",
    "# Looping through every symbols and rows\n",
    "for stock_sym in stock_prices:\n",
    "    for index, row in stock_prices[stock_sym].iterrows():\n",
    "        day = row[\"date\"]\n",
    "        volume = row[\"volume\"]\n",
    "        pair = (volume, stock_sym)\n",
    "        if day not in trades_by_day:\n",
    "            trades_by_day[day] = []\n",
    "        trades_by_day[day].append(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Finding The Most Traded Stock Each Day\n",
    "We will try and find what stock is the most traded at that particular day. As mentioned before we have stored trades for every symbol for every day in `(volume, stock_symbol)` format, thus we can actually sort it and pull the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary\n",
    "most_traded_by_day = {}\n",
    "\n",
    "# Looping through the day by day trades\n",
    "for day in trades_by_day:\n",
    "    trades_by_day[day].sort(reverse = True)\n",
    "    most_traded_by_day[day] = trades_by_day[day][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether it works or not, we will pull a couple of entries out of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151516000, 'amd')\n",
      "(32789400, 'aapl')\n",
      "(23779900, 'aapl')\n"
     ]
    }
   ],
   "source": [
    "# Checking if the result is in the correct format\n",
    "print(most_traded_by_day['2013-07-19'])\n",
    "print(most_traded_by_day['2015-12-22'])\n",
    "print(most_traded_by_day['2016-07-19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Searching For High Volume Days\n",
    "We will now find which days yield the most volume of trades. We will be limiting our findings to the 10 days with most trades by volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1964583900, '2008-01-23'),\n",
       " (1770266900, '2008-10-10'),\n",
       " (1611272800, '2007-07-26'),\n",
       " (1599183500, '2008-10-08'),\n",
       " (1578877700, '2008-01-22'),\n",
       " (1559032100, '2008-02-07'),\n",
       " (1555072400, '2008-09-29'),\n",
       " (1553880500, '2007-11-08'),\n",
       " (1536176400, '2008-01-16'),\n",
       " (1533363200, '2008-01-24')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an empty list\n",
    "daily_volumes = []\n",
    "\n",
    "# Looping through the trades day by day\n",
    "for day in trades_by_day:\n",
    "    day_volume = sum([volume for volume, _ in trades_by_day[day]])\n",
    "    daily_volumes.append((day_volume, day))\n",
    "\n",
    "# Sorting the list\n",
    "daily_volumes.sort(reverse = True)\n",
    "\n",
    "# Slicing the 10 highest by volume\n",
    "daily_volumes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Finding Profitable Stocks\n",
    "We will now try and find the most profitable stocks. To do this we will:\n",
    "1. Subtract the initial close price (first row) from the final close price (last row), then computing a percentage relative to the initial price. This will tell us how much our initial investment would have grown or shrunk.\n",
    "2. Sort all of the percentages.\n",
    "3. Find the ten stocks that grew the most in the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7483.8389225948395, 'admp'),\n",
       " (4005.0000000000005, 'adxs'),\n",
       " (3898.6004898285596, 'arcw'),\n",
       " (2437.4365640858978, 'blfs'),\n",
       " (2230.7234281466817, 'amzn'),\n",
       " (1707.3554472785036, 'anip'),\n",
       " (1549.6700659868027, 'apdn'),\n",
       " (1525.162516251625, 'cui'),\n",
       " (1339.2137535980346, 'bcli'),\n",
       " (1330.0000666666667, 'achc')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an empty list\n",
    "percentages = []\n",
    "\n",
    "# Looping through every symbol\n",
    "for sym in stock_prices:\n",
    "    data = stock_prices[sym]\n",
    "    initial = data.loc[0, 'close']\n",
    "    final = data.loc[len(data) - 1, 'close']\n",
    "    per = (final-initial)*100/initial\n",
    "    percentages.append((per, sym))\n",
    "    \n",
    "# Sorting the list\n",
    "percentages.sort(reverse = True)\n",
    "\n",
    "# Getting the top 10\n",
    "percentages[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can deduce that `ADMP` or Adamis Pharmaceuticals Corporation has the highest growth over that period of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
